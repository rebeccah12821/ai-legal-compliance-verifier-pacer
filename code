# AI Compliance Verifier Prototype with Free PACER Integration
import spacy
import pandas as pd
import requests
from datetime import datetime

class FreePACERIntegration:
    def __init__(self):
        self.base_url = "https://www.courtlistener.com/api/rest/v3/"
        self.search_url = f"{self.base_url}search/"

    def search_related_cases(self, query_term):
        params = {
            "type": "d",
            "q": f'caseName:"{query_term}"',
            "order_by": "score desc",
            "fields": "absolute_url,caseName,docketNumber,court"
        }
        
        try:
            response = requests.get(self.search_url, params=params)
            results = response.json().get('results', [])
            return [{
                'case_name': item['caseName'],
                'docket_number': item['docketNumber'],
                'court': item['court'],
                'url': f"https://www.courtlistener.com{item['absolute_url']}"
            } for item in results]
        except Exception as e:
            return [{"error": f"API Error: {str(e)}"}]

class ComplianceVerifier(FreePACERIntegration):
    def __init__(self):
        super().__init__()
        self.nlp = spacy.load("en_core_web_sm")
        self.compliance_rules = {
            'AI Disclosure': ['generated by ai', 'contains ai content',
                            'ai-assisted'],
            'IP Risks': ['patent', 'copyright', 'trade secret'],
            'Privacy Laws': ['gdpr', 'ccpa', 'hipaa']
        }
        self.history = pd.DataFrame(columns=[
            'timestamp', 'filename', 'ai_prob', 'risk_level', 'violations'
        ])
        
    def analyze_document(self, text, filename="document"):
        # Simulated AI Detection
        text_lower = text.lower()
        ai_prob = 0.2 if any(phrase in text_lower for phrase in self.compliance_rules['AI Disclosure']) else 0.85
        
        # Compliance Check
        doc = self.nlp(text_lower)
        findings = {
            'missing_disclosure': not any(
                phrase in text_lower 
                for phrase in self.compliance_rules['AI Disclosure']
            ),
            'ip_risks': [
                ent.text for ent in doc.ents 
                if ent.label_ in ['ORG', 'LAW'] and
                any(term in ent.text.lower() 
                    for term in self.compliance_rules['IP Risks'])
            ],
            'privacy_issues': [
                chunk.text for chunk in doc.noun_chunks
                if any(term in chunk.text.lower()
                       for term in self.compliance_rules['Privacy Laws'])
            ]
        }
        
        # Risk Scoring
        risk_score = ai_prob * 100
        if findings['missing_disclosure']:
            risk_score += 20
        risk_level = "High" if risk_score > 75 else "Medium" if risk_score > 50 else "Low"
        
        # Generate Report
        report = {
            'filename': filename,
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'ai_probability': f"{ai_prob:.2%}",
            'risk_score': f"{risk_score}/100",
            'risk_level': risk_level,
            'compliance_issues': {
                'missing_ai_disclosure': findings['missing_disclosure'],
                'ip_risk_entities': findings['ip_risks'],
                'privacy_law_mentions': findings['privacy_issues']
            },
            'recommendations': self._generate_recommendations(findings)
        }
        
        # Free PACER Check
        if findings['ip_risks']:
            report['pacer_check'] = []
            for ip_ref in findings['ip_risks']:
                cases = self.search_related_cases(ip_ref)
                report['pacer_check'].append({
                    'reference': ip_ref,
                    'related_cases': cases[:3]
                })
        
        # Update History
        self._update_history(report)
        
        return report
    
    def _generate_recommendations(self, findings):
        recs = []
        if findings['missing_disclosure']:
            recs.append("Add AI disclosure statement per local court rules")
        if findings['ip_risks']:
            recs.append(f"Review IP references: {', '.join(findings['ip_risks'])}")
        if findings['privacy_issues']:
            recs.append("Verify privacy law compliance with legal team")
        return recs or ["No critical issues found"]
    
    def _update_history(self, report):
        new_entry = {
            'timestamp': report['timestamp'],
            'filename': report['filename'],
            'ai_prob': report['ai_probability'],
            'risk_level': report['risk_level'],
            'violations': len(report['compliance_issues']['ip_risk_entities']) + 
                         len(report['compliance_issues']['privacy_law_mentions'])
        }
        self.history = pd.concat([self.history, pd.DataFrame([new_entry])], 
                               ignore_index=True)
    
    def generate_compliance_report(self):
        return self.history.describe().to_dict()

# Example Usage
verifier = ComplianceVerifier()
sample_doc = """This motion was prepared using AI-assisted drafting tools. 
It discusses the patent landscape surrounding neural network implementations 
(US Patent 10,000,000) and includes analysis of GDPR compliance for data 
processing systems."""
report = verifier.analyze_document(sample_doc, "motion_123.pdf")

